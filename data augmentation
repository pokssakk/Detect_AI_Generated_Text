!pip install -q transformers accelerate

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Load dataset
df = pd.read_csv("/content/drive/MyDrive/paragraph_split(6).csv")

# Filter rows where paragraph is not generated yet
df = df[df["generated"] == 0]

# Count unique titles in the filtered dataset
unique_titles = df["title"].unique()
print("Number of titles with generated == 0:", len(unique_titles))

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import random
from tqdm import tqdm
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# =====================
# Path configuration
# =====================
DATA_PATH = "/content/drive/MyDrive/paragraph_split(6).csv"
BACKUP_PATH = "/content/drive/MyDrive/generated_backup(5).csv"
FINAL_OUTPUT = "/content/drive/MyDrive/final_generated.csv"

# Title selection range (e.g., process 10,000 titles starting from index 70010)
START_INDEX = 70010
NUM_TITLES = 10000

# =====================
# Load the language model
# =====================
model_name = "kakaocorp/kanana-1.5-2.1b-instruct-2505"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)
model.eval()
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# =====================
# Step 1: Load dataset
# =====================
df = pd.read_csv(DATA_PATH)

# Step 2: Keep only non-generated paragraphs
df = df[df["generated"] == 0]

# Step 3: Extract ordered list of unique titles from the filtered dataset
ordered_titles = df["title"].tolist()  # keep order, allow duplicates
unique_ordered_titles = []
seen = set()
for t in ordered_titles:
    if t not in seen:
        seen.add(t)
        unique_ordered_titles.append(t)

# Select target titles within the given range
target_titles = unique_ordered_titles[START_INDEX:START_INDEX + NUM_TITLES]

# Step 4: Filter dataset for the selected titles only
df = df[df["title"].isin(target_titles)].copy()
remaining_titles = list(set(target_titles))

generated_data = []

# =====================
# Step 5: Paragraph generation loop
# =====================
for title in tqdm(remaining_titles, desc="Generating paragraphs"):
    group = df[df["title"] == title].reset_index(drop=True)
    if len(group) < 3:
        continue

    # Candidate positions for inserting a middle paragraph
    candidates = [i for i in range(1, len(group) - 1)]
    if not candidates:
        continue

    middle_idx = random.choice(candidates)
    before = group.loc[middle_idx - 1, "paragraph_text"]
    after = group.loc[middle_idx + 1, "paragraph_text"]

    # Prompt design
    prompt = (
        "Below are the preceding and following paragraphs from a Wikipedia article. "
        "Write a paragraph that naturally connects these two, without repeating content from the original paragraphs, "
        "and expand on the context logically.\n"
        "- Ensure logical flow and coherence.\n"
        "- Avoid conversational tone, questions, or bullet lists. Write in complete sentences.\n"
        "- The paragraph should contain 2â€“6 sentences.\n"
        "- Write as a single paragraph only.\n\n"

